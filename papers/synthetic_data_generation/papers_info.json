{
  "2403.16244v1": {
    "title": "On the Equivalency, Substitutability, and Flexibility of Synthetic Data",
    "authors": [
      "Che-Jui Chang",
      "Danrui Li",
      "Seonghyeon Moon",
      "Mubbasir Kapadia"
    ],
    "summary": "We study, from an empirical standpoint, the efficacy of synthetic data in\nreal-world scenarios. Leveraging synthetic data for training perception models\nhas become a key strategy embraced by the community due to its efficiency,\nscalability, perfect annotations, and low costs. Despite proven advantages, few\nstudies put their stress on how to efficiently generate synthetic datasets to\nsolve real-world problems and to what extent synthetic data can reduce the\neffort for real-world data collection. To answer the questions, we\nsystematically investigate several interesting properties of synthetic data --\nthe equivalency of synthetic data to real-world data, the substitutability of\nsynthetic data for real data, and the flexibility of synthetic data generators\nto close up domain gaps. Leveraging the M3Act synthetic data generator, we\nconduct experiments on DanceTrack and MOT17. Our results suggest that synthetic\ndata not only enhances model performance but also demonstrates substitutability\nfor real data, with 60% to 80% replacement without performance loss. In\naddition, our study of the impact of synthetic data distributions on downstream\nperformance reveals the importance of flexible data generators in narrowing\ndomain gaps for improved model adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2403.16244v1",
    "published": "2024-03-24"
  },
  "2212.10310v2": {
    "title": "PreFair: Privately Generating Justifiably Fair Synthetic Data",
    "authors": [
      "David Pujol",
      "Amir Gilad",
      "Ashwin Machanavajjhala"
    ],
    "summary": "When a database is protected by Differential Privacy (DP), its usability is\nlimited in scope. In this scenario, generating a synthetic version of the data\nthat mimics the properties of the private data allows users to perform any\noperation on the synthetic data, while maintaining the privacy of the original\ndata. Therefore, multiple works have been devoted to devising systems for DP\nsynthetic data generation. However, such systems may preserve or even magnify\nproperties of the data that make it unfair, endering the synthetic data unfit\nfor use. In this work, we present PreFair, a system that allows for DP fair\nsynthetic data generation. PreFair extends the state-of-the-art DP data\ngeneration mechanisms by incorporating a causal fairness criterion that ensures\nfair synthetic data. We adapt the notion of justifiable fairness to fit the\nsynthetic data generation scenario. We further study the problem of generating\nDP fair synthetic data, showing its intractability and designing algorithms\nthat are optimal under certain assumptions. We also provide an extensive\nexperimental evaluation, showing that PreFair generates synthetic data that is\nsignificantly fairer than the data generated by leading DP data generation\nmechanisms, while remaining faithful to the private data.",
    "pdf_url": "http://arxiv.org/pdf/2212.10310v2",
    "published": "2022-12-20"
  },
  "2506.13818v1": {
    "title": "The Synthetic Mirror -- Synthetic Data at the Age of Agentic AI",
    "authors": [
      "Marcelle Momha"
    ],
    "summary": "Synthetic data, which is artificially generated and intelligently mimicking\nor supplementing the real-world data, is increasingly used. The proliferation\nof AI agents and the adoption of synthetic data create a synthetic mirror that\nconceptualizes a representation and potential distortion of reality, thus\ngenerating trust and accountability deficits. This paper explores the\nimplications for privacy and policymaking stemming from synthetic data\ngeneration, and the urgent need for new policy instruments and legal framework\nadaptation to ensure appropriate levels of trust and accountability for AI\nagents relying on synthetic data. Rather than creating entirely new policy or\nlegal regimes, the most practical approach involves targeted amendments to\nexisting frameworks, recognizing synthetic data as a distinct regulatory\ncategory with unique characteristics.",
    "pdf_url": "http://arxiv.org/pdf/2506.13818v1",
    "published": "2025-06-15"
  },
  "1909.11512v1": {
    "title": "Synthetic Data for Deep Learning",
    "authors": [
      "Sergey I. Nikolenko"
    ],
    "summary": "Synthetic data is an increasingly popular tool for training deep learning\nmodels, especially in computer vision but also in other areas. In this work, we\nattempt to provide a comprehensive survey of the various directions in the\ndevelopment and application of synthetic data. First, we discuss synthetic\ndatasets for basic computer vision problems, both low-level (e.g., optical flow\nestimation) and high-level (e.g., semantic segmentation), synthetic\nenvironments and datasets for outdoor and urban scenes (autonomous driving),\nindoor scenes (indoor navigation), aerial navigation, simulation environments\nfor robotics, applications of synthetic data outside computer vision (in neural\nprogramming, bioinformatics, NLP, and more); we also survey the work on\nimproving synthetic data development and alternative ways to produce it such as\nGANs. Second, we discuss in detail the synthetic-to-real domain adaptation\nproblem that inevitably arises in applications of synthetic data, including\nsynthetic-to-real refinement with GAN-based models and domain adaptation at the\nfeature/model level without explicit data transformations. Third, we turn to\nprivacy-related applications of synthetic data and review the work on\ngenerating synthetic datasets with differential privacy guarantees. We conclude\nby highlighting the most promising directions for further work in synthetic\ndata studies.",
    "pdf_url": "http://arxiv.org/pdf/1909.11512v1",
    "published": "2019-09-25"
  },
  "2310.17848v3": {
    "title": "Boosting Data Analytics With Synthetic Volume Expansion",
    "authors": [
      "Xiaotong Shen",
      "Yifei Liu",
      "Rex Shen"
    ],
    "summary": "Synthetic data generation, a cornerstone of Generative Artificial\nIntelligence, promotes a paradigm shift in data science by addressing data\nscarcity and privacy while enabling unprecedented performance. As synthetic\ndata becomes more prevalent, concerns emerge regarding the accuracy of\nstatistical methods when applied to synthetic data in contrast to raw data.\nThis article explores the effectiveness of statistical methods on synthetic\ndata and the privacy risks of synthetic data. Regarding effectiveness, we\npresent the Synthetic Data Generation for Analytics framework. This framework\napplies statistical approaches to high-quality synthetic data produced by\ngenerative models like tabular diffusion models, which, initially trained on\nraw data, benefit from insights from pertinent studies through transfer\nlearning. A key finding within this framework is the generational effect, which\nreveals that the error rate of statistical methods on synthetic data decreases\nwith the addition of more synthetic data but may eventually rise or stabilize.\nThis phenomenon, stemming from the challenge of accurately mirroring raw data\ndistributions, highlights a \"reflection point\"-an ideal volume of synthetic\ndata defined by specific error metrics. Through three case studies, sentiment\nanalysis, predictive modeling of structured data, and inference in tabular\ndata, we validate the superior performance of this framework compared to\nconventional approaches. On privacy, synthetic data imposes lower risks while\nsupporting the differential privacy standard. These studies underscore\nsynthetic data's untapped potential in redefining data science's landscape.",
    "pdf_url": "http://arxiv.org/pdf/2310.17848v3",
    "published": "2023-10-27"
  }
}